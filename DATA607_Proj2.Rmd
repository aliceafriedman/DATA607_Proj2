---
title: "DATA607_Proj2"
author: "Alice Friedman"
date: "October 7, 2018"
output:   html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
remove(list = ls())
```
  
##Setup
  
  
1. Load required libraries
  
```{r, results = "hide", message=FALSE, warning=FALSE}
library(RCurl)
library(xml2)
library(rvest)
library(dplyr)
library(stringr)
library(tidyr)
library(knitr)
library(ggplot2)
```
  
  
  
  
##Dataset #1: Wikipedia Table of Simpsons Seasons 
  
###1.1 Scrape HTML from web using data from HTML using ```rvest``` package
  
The ```read_html``` function in the rvest package takes a URL and creates an object in R containing all the HTML code used to write the website. Creating a local object is the first step to parsing scraped web data.
  
```{r}
# Read the HTML file
html <- read_html("https://en.wikipedia.org/wiki/List_of_The_Simpsons_episodes")
```
  
  
###1.2 Extract data from HTML using ```rvest``` package
  
Using the rvest package, we can:
  
  1. Extract all of the html "table" nodes into an R table called "Simpsons.table"
  
    - This will create a table where each row is the HTML code starting with "\<table ...""
  
  2. Create an R table with the from the row of Simpsons.table, which contains the information on the Seasons
  
    - ```html_table``` will produce a list with length 1--this is not useful for our analysis
    
    - To create a data frame, we will use the ```as.data.frame()``` function in the pipe
    
```{r}
#(Credit for inspiration for code from StackOverflow: https://stackoverflow.com/questions/1395528/scraping-html-tables-into-r-data-frames-using-the-xml-package))
Simpsons.tables<-html_nodes(html, "table")
Seasons.raw <- html_table(Simpsons.tables[1], fill = TRUE) %>% as.data.frame() %>% glimpse()
head(Seasons.raw)
```
  
  
###1.3 Clean data using dplyr package

There are a few errors generated by the extraction and original format of the table that require cleaning to produce a tidy data set:
  
1. The first column is empty, and there is an extra "Episodes" column (resulting from the formatting with an extra merged header column at row 19)

2. The "Film" row is not information about a season of the TV show---this row will be removed.

3. The first row is really column names and not all of the column names are correctly extracted from the HTMl---this is because the original table uses a nested header

4. Several columns have extra text, which were links to footnotes in the original webpage
  
5. The ratings column lists information with two different units---these should be split into  two different variables
  
6. Dates are given as text and as YYYY-MM-DD in the same column. 
  
7. Several columns give numeric information that is classified as character

  
We will tidy these errors one at a time in the code below.
  
####1.3.1 Drop empty, duplicate columns
  
Using the ```dplyr``` package, we can drop the empty column and rename the columns correctly.
  
```{r}
Seasons <- Seasons.raw %>% select(-Season, -Episodes.1) %>% glimpse()
```
  
  
####1.3.2 Drop extraneous "Film" row
  
  
```{r}
#Drop "Film"" row using filter from dplyr and the "not" operater "!"
Seasons <- Seasons %>% filter(Episodes!="Film")
```
  
  
####1.3.3 Correct column names, drop duplicate column names row
  
The second header column in the original table contains some more relevant variable information, but is not exactly correct either. This was coded as the first row of data in our extaction process. We will drop the dupilicate first row, then clean up any remaining visible errros manually.
    
```{r}
#Drop first row
Seasons = Seasons[-1,]

#Manually correct remaining column names using position, due to duplicate column names
names(Seasons)
Seasons <- rename(Seasons, 
       Season = 1,
       "First aired" = 3,
       "Last aired" = 4,
       Ratings = 5,
       Rank = 6,
       Ratings.Score = 7
       )  
names(Seasons)
```
  
  
  
####1.3.4 Remove footnote references from table cells
  
This can be done using a RegEx and ```str_remove_all()``` from the ```stringr``` pacakge. Because the footnotes are coded with square brackets, however, this is tricky! 

Double backslashes are needed to escape each bracket:  ```"\\[..\\]"```
  
```{r}
Seasons$Ratings <- str_remove_all(Seasons$Ratings, "(\\[)..\\]")
Seasons$Rank <- str_remove_all(Seasons$Rank, "(\\[)..\\]")
```
  
  
####1.3.5 Split Ratings column into two variables: Households and Viewers
  
Because househoulds and viewers are entirely different types of measurements, I would like to split the "Ratings" column into 2, where each row has "NA" for the data type not measured. We can do this by first extracting the data type from the "Ratings" column, and then using the ```tidyr``` package to ```spread``` the data into two columns, "Household Ratings" and "Viewers."

Lastly, because this is numeric data, we will remove all string information from the columns and reclassify the data using the ```as.numeric``` function.
```{r}
Seasons <- Seasons %>% 
  mutate(
    Ratings.Type = str_extract(Ratings, "(households)|(viewers)"),
    Ratings = str_remove(Ratings, "(households)|(viewers)"))

Seasons <- Seasons %>% 
#Extract numeric information from Ratings
  mutate(Ratings = as.numeric(str_extract(Ratings, "[[:digit:]]+(\\.)[[:digit:]]"))) %>% 
#Split Ratings into columns by rating type
  spread(Ratings.Type, Ratings) %>% 
#Rename columns
  rename(Ratings.Millions.Households = households, Ratings.Millions.Viewers = viewers) %>% 
#Drop empty column
  select(-9) %>% 
  glimpse()
```  
  
###1.3.6 Extract date information from columns including dates
  
Lastly, we will remove the duplicate date information in the two columns with dates, and reclassify the date information as a date with ```as.Date( )```
  
```{r}
Seasons <- Seasons %>% 
#Extract numeric information from Ratings
  mutate(
    `First aired` = as.Date(str_extract(`First aired`, "[[:digit:]]{4}-[[:digit:]]{2}-[[:digit:]]{2}")),
    `Last aired` = as.Date(str_extract(`Last aired`, "[[:digit:]]{4}-[[:digit:]]{2}-[[:digit:]]{2}"))
    ) 
```
  

####1.3.7 Reclassify numeric data from text
```{r}
Seasons <- Seasons %>% 
  mutate(Rank = as.numeric(str_extract(Rank, "[[:digit:]]+")),
         Season = as.numeric(Season),
         Episodes = as.numeric(Episodes),
         Ratings.Score = as.numeric(Ratings.Score)
  ) %>% 
#Arrange by Season, now that data is properly classified
  arrange(Season)
          
```
  
  
###1.4 Cleaned data table  
```{r}
kable(Seasons, caption = "Simposons Seasons, via Wikipedia")
```
  
###1.5 Analysis
  
Whew! What a lot of work. Now that our data is clean, we can perform some analysis.
  
How has *The Simpsons's* rank changed with the change in ratings? For simplicity, we will look at ratings scored as millions of households and millions of viewers, separately.

Per the tables below, it looks like---as expected--- the higher the number of ratings, the lower (better) thank national ranking. Interestingly, this relationship is much tighted when looking at viewers than households---perhaps why Nielson switched metrics!

```{r}
Seasons %>% 
  filter(!is.na(Ratings.Millions.Households)) %>% 
  ggplot(aes(x=Ratings.Millions.Households, y=Rank))+
  geom_jitter()+
  geom_smooth(method=lm)+
  labs(
    x="Nielson Ratings (Millions of Households)",
    title="Relationship between Nielson Ratings", 
    subtitle="by Household and National Ratings Ranking",
    caption="Source: 'https://en.wikipedia.org/wiki/List_of_The_Simpsons_episodes'")


Seasons %>% 
  filter(!is.na(Ratings.Millions.Viewers)) %>% 
  ggplot(aes(x=Ratings.Millions.Viewers, y=Rank))+
  geom_jitter()+
  geom_smooth(method=lm)+
  labs(
    x="Nielson Ratings (Millions of Viewers)",
    title="Relationship between Nielson Ratings", 
    subtitle="by Viewers and National Ratings Ranking",
    caption="Source: 'https://en.wikipedia.org/wiki/List_of_The_Simpsons_episodes'")

```